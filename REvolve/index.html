<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
<!--  <meta name="description"-->
<!--        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">-->
<!--  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">-->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>REvolve: Reward Evolution with Large Language Models for Autonomous Driving</title>

<meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Five Videos Side by Side</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.3/css/bulma.min.css">
    <style>
        .video-container {
            display: flex;
            justify-content: space-between;
            width: 80vw; /* Full viewport width */
            position: relative;
            left: 50%;
            transform: translateX(-50%);
        }
        .video-container .column {
            flex: 1;
            padding: 5px;
        }
        .video-container video {
            height: 200px; /* Set the height you want */
            width: 100%;
            object-fit: cover; /* Ensure the video covers the area */
        }
    </style>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    .custom-video-height {
        height: 400px; /* Set the desired height */
        width: 800px; /* Set the desired width */
        max-width: 100%; /* Ensures video doesn't overflow the container */
        max-height: 100%; /* Ensures video doesn't overflow the container */
        object-fit: cover; /* Adjusts the content if the aspect ratio is different */
    }
  </style>

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Video Carousel</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.3/css/bulma.min.css">
    <style>
        .carousel-container {
            overflow: hidden;
            width: 50vw; /* Full viewport width */
            position: relative;
            left: 50%;
            transform: translateX(-50%);
        }
        .carousel-track {
            display: flex;
            transition: transform 0.5s ease;
        }
        .carousel-item {
            min-width: calc(100% / 3); /* Adjust to show 3 items at a time */
            box-sizing: border-box;
            padding: 5px;
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        .carousel-item video {
            width: 100%;
            height: 200px;
            object-fit: cover;
        }
        .carousel-buttons {
            position: absolute;
            top: 50%;
            width: 100%;
            display: flex;
            justify-content: space-between;
            transform: translateY(-50%);
        }
        .carousel-button {
            background: white;
            border: 2px solid gray;
            border-radius: 50%;
            width: 50px;
            height: 50px;
            display: flex;
            justify-content: center;
            align-items: center;
            cursor: pointer;
            font-size: 24px;
        }
        .carousel-button svg {
            width: 20px;
            height: 20px;
            fill: gray;
        }
        .carousel-dots {
            display: flex;
            justify-content: center;
            margin-top: 10px;
        }
        .carousel-dot {
            height: 10px;
            width: 10px;
            margin: 0 5px;
            background-color: gray;
            border-radius: 50%;
            display: inline-block;
            cursor: pointer;
        }
        .carousel-dot.active {
            background-color: black;
        }
    </style>
<!--  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.3/css/bulma.min.css">-->

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
<!--  <link rel="icon" href="./static/images/favicon.svg">-->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">REvolve: Reward Evolution with Large Language Models for Autonomous Driving</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://rishihazra.github.io/">Rishi Hazra</a><sup>*</sup>,</span>
            <span class="author-block">
              <a href="https://mpi.aass.oru.se/alkis-sygkounas/">Alkis Sygkounas</a><sup>*</sup>,</span>
            <span class="author-block">
              <a href="https://mpi.aass.oru.se/andreas-persson/">Andreas Persson</a>,
            </span>
            <span class="author-block">
              <a href="https://mpi.aass.oru.se/amy-loutfi/">Amy Loutfi</a>,
            </span>
             <span class="author-block">
              <a href="https://pedrozudo.github.io/">Pedro Zuidberg Dos Martires</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"> Centre for Applied Autonomous Sensor Systems (AASS), Ã–rebro University, Sweden</span>
          </div>

           <div class="is-size-6 publication-authors">
            <span class="author-block"><sup>*</sup>equal contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://rishihazra.github.io/publications/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://rishihazra.github.io/publications/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://rishihazra.github.io/publications/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" class="custom-video-height" autoplay muted loop playsinline>
        <source src="./static/videos/revolve.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Autonomous Driving agent trained with REvolve-designed rewards.
      </h2>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Designing effective reward functions is crucial to training reinforcement learning (RL) algorithms.
            However, this design is non-trivial, even for domain experts, due to the subjective nature of certain
            tasks that are hard to quantify explicitly. In recent works, large language models (LLMs) have been used
            for reward generation from natural language task descriptions, leveraging their extensive instruction
            tuning and commonsense understanding of human behavior. In this work, we hypothesize that LLMs, guided
            by human feedback, can be used to formulate <i>human-aligned</i> reward functions. Specifically,
            we study this in the challenging setting of autonomous driving (AD), wherein notions of "good" driving
            are tacit and hard to quantify. To this end, we introduce REvolve, an evolutionary framework that uses
            LLMs for reward design in AD. REvolve creates and refines reward functions by utilizing human feedback
            to guide the evolution process, effectively translating implicit human knowledge into explicit reward
            functions for training (deep) RL agents. We demonstrate that agents trained on REvolve-designed rewards
            align closely with human driving standards, thereby outperforming other state-of-the-art baselines.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-fullwidth">
        <h2 class="title is-3">REvolve Overview</h2>
        <div class="content has-text-justified">
            <img src="./static/images/rewolve-overview.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Given the task of autonomous driving and abstracted environment variables,
              a reward designer \(G\) (LLM) outputs a population of reward functions, each used to train an AD policy
              \(\pi(R)\) in driving simulation. Then, we collect human preferences and natural language feedback on
              pairs of policy rollouts \(\theta \sim \Theta_{\pi(R)}\) through a human user feedback interface.
              Policy (and thus, corresponding reward function) fitness \(\sigma\) is calculated, and the fittest
              individuals, along with their NL feedback \(\lambda\), are refined by \(G\). The process leverages
              genetic programming for evolution. The flames symbolize trainable parameters.</p>
          </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-fullwidth">
<!--        <h2 class="title is-3">REwolve Overview</h2>-->
        <div class="content has-text-justified">
          <p>REvolve offers several key advantages:
          <br>
          <b>(1) Framing reward design as a search problem.</b> Compared to <i>greedy search</i> in Eureka, REvolve uses Genetic Programming to
           prevents premature convergence without incurring additional computational costs.

            <br>

          <b>(2) Utilizing human feedback to guide the search.</b> Human preference data is directly mapped into fitness scores,
            effectively allowing humans to serve as fitness functions.

            <br>

          <b>(3) Eliminating the need for additional reward model training.</b> Unlike RLHF, REvolve requires no reward
            model and output reward functions are interpretable.</p>
          </div>
      </div>
    </div>
  </div>

  <br>
  <br>

  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
<!--        <h2 class="title is-3">REvolve Overview</h2>-->
        <div class="content has-text-justified">
            <img src="./static/images/mutation_crossover_alternative-1.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
          <p>Illustration of how GPT-4 applies mutation and crossover to reward functions.
            Mutation (left): shows the modification of the "smoothness reward" component.
            A red `-' sign indicates the line removed from the parent reward function, while a green `+'
            sign indicates the line added to the new reward function.
            Crossover (right): demonstrates how parent reward functions are combined to create a child reward function,
            incorporating the most effective reward components from each parent.</p>
          </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-fullwidth">
<!--        <h2 class="title is-3">REwolve Overview</h2>-->
        <div class="content has-text-justified">
          The four main steps in REvolve are:
          <br>
          <b>Initilization:</b> We start by initializing a reward database with K reward function individuals using GPT-4.
          <br>
          <b>Reproduction:</b> Each successive generation of K individuals is created by applying genetic operators
          (crossover and mutation), on the existing reward database individuals.
          <br>
          <b>Selection:</b> Newly reproduced individuals are retained based on fitness scores,
          following a <i>survival of the fittest</i> approach. To compute the fitness score \(\sigma\),
          we ask human evaluators to judge policy rollouts from different policies in a pairwise fashion.
          <br>
          <b>Termination:</b> The evolutionary process repeats until it reaches a predetermined number of generations \(N\) ,
          or when an individual attains a fitness score equivalent to human-level driving performance.
          </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Results</h2>
    </div>
    <div class="columns is-centered">
          <!-- Visual Effects. -->
        <div class="column">
          <div class="content">
  <!--          <h2 class="title is-3">REwolve vs. Baseline</h2>-->
            <img src="./static/images/fitness_combined.png"
                   class="interpolation-image"
                   alt="Interpolate start reference image."/>
          </div>
        </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-fullwidth">
<!--        <h2 class="title is-3">REwolve Overview</h2>-->
        <div class="content has-text-justified">
          <p>
          <b>How does REvolve fair against the baselines on manually designed fitness scores?</b>
            REvolve exhibits continuous improvement across successive generations, ultimately achieving a higher fitness score on the manually designed fitness scale.

            <br>

          <b>Do human fitness scores induce human-aligned behavior?</b>
            REvolve policies secure second and third Elo ranks, surpassed only by Human Driving.

            <br>

          <b>How does REvolve affect policy learning?</b>
            REvolve-designed rewards converge to a higher number of episodic steps compared to expert-designed rewards,
            signifying a higher rate of successful actions per episode.
            <br>

          <b>Do REvolve-designed reward functions generalize to new environments?</b>
            In two novel environments -- (Env 1) featuring lanes and a completely altered landscape,
            and (Env2) characterized by increased traffic with multiple cars actively maneuvering -- REvolve outperforms expert-designed rewards.

          </p>
          </div>
      </div>
    </div>
<!--  </div>-->

      <!--/ Visual Effects. -->


<!--<section class="hero is-light is-small">-->
<!--        <div class="hero-body">-->
<!--            <div class="container is-fluid">-->
<!--                <div class="columns video-container">-->
<!--                    <div class="column">-->
<!--                        <video poster="" id="human-driving" autoplay controls muted loop playsinline>-->
<!--                            <source src="./static/videos/human_driving.mp4" type="video/mp4">-->
<!--                        </video>-->
<!--                      <p>Human Driving</p>-->
<!--                    </div>-->
<!--                    <div class="column">-->
<!--                        <video poster="" id="revolve" autoplay controls muted loop playsinline>-->
<!--                            <source src="./static/videos/revolve.mp4" type="video/mp4">-->
<!--                        </video>-->
<!--                      <p>REvolve</p>-->
<!--                    </div>-->
<!--                   <div class="column">-->
<!--                        <video poster="" id="revolve-auto" autoplay controls muted loop playsinline>-->
<!--                            <source src="./static/videos/revolve_auto.mp4" type="video/mp4">-->
<!--                        </video>-->
<!--                      <p>REvolve Auto</p>-->
<!--                    </div>-->
<!--                    <div class="column">-->
<!--                        <video poster="" id="eureka" autoplay controls muted loop playsinline>-->
<!--                            <source src="./static/videos/eureka.mp4" type="video/mp4">-->
<!--                        </video>-->
<!--                      <p>Eureka</p>-->
<!--                    </div>-->
<!--                  <div class="column">-->
<!--                        <video poster="" id="eureka-auto" autoplay controls muted loop playsinline>-->
<!--                            <source src="./static/videos/eureka_auto.mp4" type="video/mp4">-->
<!--                        </video>-->
<!--                      <p>Eureka Auto</p>-->
<!--                    </div>-->
<!--                </div>-->
<!--            </div>-->
<!--        </div>-->
    <br>
    <br>
     <div class="hero-body">
        <div class="container is-fluid">
            <div class="carousel-container">
                <div class="carousel-track">
                    <div class="carousel-item">
                        <video poster="" id="human-driving" autoplay controls muted loop playsinline>
                            <source src="./static/videos/human_driving.mp4" type="video/mp4">
                        </video>
                        <p>Human Driving</p>
                    </div>
                    <div class="carousel-item">
                        <video poster="" id="revolve" autoplay controls muted loop playsinline>
                            <source src="./static/videos/revolve.mp4" type="video/mp4">
                        </video>
                        <p>REvolve</p>
                    </div>
                    <div class="carousel-item">
                        <video poster="" id="revolve-auto" autoplay controls muted loop playsinline>
                            <source src="./static/videos/revolve_auto.mp4" type="video/mp4">
                        </video>
                        <p>REvolve Auto</p>
                    </div>
                    <div class="carousel-item">
                        <video poster="" id="eureka" autoplay controls muted loop playsinline>
                            <source src="./static/videos/eureka.mp4" type="video/mp4">
                        </video>
                        <p>Eureka</p>
                    </div>
                    <div class="carousel-item">
                        <video poster="" id="eureka-auto" autoplay controls muted loop playsinline>
                            <source src="./static/videos/eureka_auto.mp4" type="video/mp4">
                        </video>
                        <p>Eureka Auto</p>
                    </div>
                </div>
                <div class="carousel-buttons">
                    <button class="carousel-button" id="prevBtn">
                        <svg viewBox="0 0 24 24">
                            <path d="M15.41 7.41L14 6l-6 6 6 6 1.41-1.41L10.83 12z"/>
                        </svg>
                    </button>
                    <button class="carousel-button" id="nextBtn">
                        <svg viewBox="0 0 24 24">
                            <path d="M8.59 16.59L10 18l6-6-6-6-1.41 1.41L13.17 12z"/>
                        </svg>
                    </button>
                </div>
                <div class="carousel-dots">
                    <!-- Dots will be dynamically added by JavaScript -->
                </div>
            </div>
        </div>

        <div class="columns is-centered has-text-centered">
            <div class="column is-fullwidth">
                <div class="content has-text-justified">
                    <p><br>
                    Comparison of Human Driving with rollouts from policies trained with REvolve and Eureka-designed reward functions.
                    REvolve-designed rewards lead to no collisions, smoother driving, better lane following, and better turn handling at intersections, compared to Eureka.
                    </p>
                </div>
            </div>
        </div>
    </div>

    <script>
        const track = document.querySelector('.carousel-track');
        const nextButton = document.getElementById('nextBtn');
        const prevButton = document.getElementById('prevBtn');
        const items = document.querySelectorAll('.carousel-item');
        const dotsContainer = document.querySelector('.carousel-dots');
        let currentIndex = 0;
        const visibleCount = 3; // Number of videos visible at a time

        function createDots() {
            for (let i = 0; i < items.length; i++) {
                const dot = document.createElement('span');
                dot.classList.add('carousel-dot');
                if (i === 0) dot.classList.add('active');
                dot.dataset.index = i;
                dotsContainer.appendChild(dot);
            }
        }

        function updateDots() {
            const dots = document.querySelectorAll('.carousel-dot');
            dots.forEach(dot => dot.classList.remove('active'));
            dots[currentIndex].classList.add('active');
        }

        nextButton.addEventListener('click', () => {
            if (currentIndex < items.length - visibleCount) {
                currentIndex++;
            } else {
                currentIndex = 0;
            }
            track.style.transform = `translateX(-${currentIndex * (100 / visibleCount)}%)`;
            updateDots();
        });

        prevButton.addEventListener('click', () => {
             if (currentIndex > 0) {
                currentIndex--;
            } else {
                currentIndex = items.length - visibleCount;
            }
            track.style.transform = `translateX(-${currentIndex * (100 / visibleCount)}%)`;
            updateDots();
        });

        dotsContainer.addEventListener('click', (e) => {
            if (e.target.classList.contains('carousel-dot')) {
                const index = parseInt(e.target.dataset.index);
                currentIndex = index;
                track.style.transform = `translateX(-${currentIndex * 100}%)`;
                updateDots();
            }
        });

        createDots();
    </script>
  </div>

  <br>
  <br>
  <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
<!--            <div class="column is-four-fifths">-->
                <div class="content has-text-justified">
                  <img src="./static/images/revolve-best-reward.png"
                       class="interpolation-image"
                       alt="Interpolate start reference image."/>
                </div>
                <div class="content has-text-justified">
                  <img src="./static/images/revolve-auto-best-reward.png"
                       class="interpolation-image"
                       alt="Interpolate start reference image."/>
                </div>
        </div>
        <div class="columns is-centered has-text-centered">
          <div class="column is-fullwidth">
    <!--        <h2 class="title is-3">REwolve Overview</h2>-->
            <div class="content has-text-justified">
              <p>
              Best (based on fitness evaluations) reward functions \(R^\ast\) from REvolve and REvolve Auto.
                It can be observed that each reward function component and their aggregation is interpretable.
                Hence, they can be scrutinized and tweaked if necessary to meet safety standards.
              </p>
              </div>
          </div>
        </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Comparison with other AD frameworks</h2>
        <div class="content has-text-justified">
            <img src="./static/images/rewolve-comparison.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
          </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-fullwidth">
<!--        <h2 class="title is-3">REwolve Overview</h2>-->
        <div class="content has-text-justified">
          <p>Comparison of REvolve with existing frameworks used to train AD agents. (a.) Expert Designed reward function
              \(R\) to train the AD agent; (b.) learning from demonstrations (LfD) and learning from interventions (LfI),
              where the agent is trained to imitate the human; (c.) humans acting as reward functions within the training loop,
              by assessing policy rollouts and providing scalar rewards, which requires significant manual effort;
              (d.) Reinforcement learning from human feedback (RLHF), where human preference data is used to train an
              additional (black-box) reward model. This reward model is used as a proxy for human rewards to train the AD policy;
              (e) Proposed REvolve, which uses GPT-4 as a reward function generator \(G\) and evolves them based on (minimal)
              human feedback on the rollouts sampled from the trained models. This feedback is directly incorporated into
              the reward design process. REvolve outputs interpretable reward functions, thereby avoiding learning an
              additional reward model. Here, \(\pi \in \Pi\) is a trainable policy in the set of policies \(\Pi\).
              The trainable blocks are denoted by the symbol of the flame.
          </p>
          </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{hazra2024revolve,
  author    = {Hazra, Rishi and Sygkounas, Alkis and Persson, Andreas and Martires, Pedro Zuidberg Dos and Loutfi, Amy},
  title     = {REvolve: Reward Evolution with Large Language Models for Autonomous Driving},
  journal   = {preprint},
  year      = {2024},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            The website template is borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
